from nltk.tokenize import sent_tokenize, word_tokenize, WordPunctTokenizer

input_text1=("No, sir - house was almost destroyed, but I got him out all right before the Muggles started swarmin' around. He fell asleep as we was flyin' over Bristol.")

print("\nSentence Tokenizer : ")
print(sent_tokenize(input_text1))
print("\nWord Tokenizer : ")
print(word_tokenize(input_text1))
print("\nWord Punct Tokenizer :")
print(WordPunctTokenizer().tokenize(input_text1))


input_text2="\"I suppose we could take him to the zoo,\"said Aunt Petunia slowly,\"... and leave him in the car. ...\""

print("\nSentence Tokenizer : ")
print(sent_tokenize(input_text2))
print("\nWord Tokenizer : ")
print(word_tokenize(input_text2))
print("\nWord Punct Tokenizer :")
print(WordPunctTokenizer().tokenize(input_text2))


input_text3="Just then, the doorbell rang - \"Oh, good Lord, they're here!\" said Aunt Petunia frantically - and a moment late,, Dudley's best friend, Piers Polkiss, walked in with his mother. Piers was a scrawny boy with a face like a rat. He was usually the one who held people's arms behind their backs while Dudley hit them. Dudley stopped pretending to cry at once."

print("\nSentence Tokenizer : ")
print(sent_tokenize(input_text3))
print("\nWord Tokenizer : ")
print(word_tokenize(input_text3))
print("\nWord Punct Tokenizer :")
print(WordPunctTokenizer().tokenize(input_text3))

